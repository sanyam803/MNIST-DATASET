{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from os.path import isfile, isdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANYAM\\Documents\\mnist_dataset\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\SANYAM\\Documents\\mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8    ...         pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0    ...     42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0    ...         0.219286      0.117095   \n",
       "std        0.0      0.0      0.0    ...         6.312890      4.633819   \n",
       "min        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "max        0.0      0.0      0.0    ...       254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.shape,test.shape)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "5      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "5       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "5         0         0         0         0         0  \n",
       "\n",
       "[6 rows x 785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels_counts=train['label'].value_counts(sort=False)\n",
    "unique_labels_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.cond()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casting to numpy array\n",
    "train_Data=train.values[:,1:];\n",
    "train_Labels=train.values[:,0];\n",
    "test_Data=test.values[:,1:];\n",
    "test_Labels=test.values[:,0];\n",
    "test_Data.shape\n",
    "train_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "    '''\n",
    "    min -max scaling for every image\n",
    "    data : numpy array\n",
    "    output : scaled numpy array\n",
    "    '''\n",
    "    minV=0;\n",
    "    maxV=255;\n",
    "    data=(data-minV)/(maxV-minV);\n",
    "    return data;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, numberOfClass):\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(range(numberOfClass))\n",
    "    return lb.transform(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedTrainData = preprocessing_data(train_Data)\n",
    "processedTestData = preprocessing_data(test_Data)\n",
    "one_hot_trainLabel = one_hot_encoding(train_Labels, 10);\n",
    "one_hot_testLabel = one_hot_encoding(test_Labels, 10);\n",
    "processedTrainData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Network With Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initializer_parameters(features,weight_nodes,g):\n",
    "    \"\"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow\n",
    "                       \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    with  g.as_default():\n",
    "        W1=tf.get_variable(\"W1\",initializer = tf.contrib.layers.xavier_initializer(seed = 1),shape=(features,weight_nodes[0]));\n",
    "        W2=tf.get_variable(\"W2\",initializer = tf.contrib.layers.xavier_initializer(seed = 1),shape=(weight_nodes[0],weight_nodes[1]));\n",
    "        W3=tf.get_variable(\"W3\",initializer = tf.contrib.layers.xavier_initializer(seed = 1),shape=(weight_nodes[1],weight_nodes[2]));\n",
    "        b1 = tf.get_variable(\"b1\", shape=(1,weight_nodes[0]), initializer = tf.zeros_initializer());\n",
    "        b2 = tf.get_variable(\"b2\", shape=(1,weight_nodes[1]), initializer = tf.zeros_initializer())\n",
    "        b3 = tf.get_variable(\"b3\", shape=(1,weight_nodes[2]), initializer = tf.zeros_initializer());\n",
    "        parameters1={};\n",
    "        parameters1[\"W1\"]=W1;\n",
    "        parameters1[\"W2\"]=W2;\n",
    "        parameters1[\"W3\"]=W3;\n",
    "        parameters1[\"b1\"]=b1;\n",
    "        parameters1[\"b2\"]=b2;\n",
    "        parameters1[\"b3\"]=b3;\n",
    "    return parameters1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholder(features,classes,g):\n",
    "    \"\"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "  \n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, features] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None,classes] and dtype \"float\"\"\n",
    "    \"\"\"\n",
    "    with g.as_default():\n",
    "        X1 = tf.placeholder(dtype=tf.float32,shape=(None,features));\n",
    "        Y1= tf.placeholder(dtype=tf.float32,shape=(None,classes));\n",
    "        keep_prob = tf.placeholder(dtype = tf.float32,name=\"keep_prob\");\n",
    "        l2_regulization=tf.placeholder(dtype=tf.int32,name=\"l2\");\n",
    "    return X1,Y1,keep_prob,l2_regulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propogation(parameters,X,g,keep_prob):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR \n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing  parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "    g --current graph\n",
    "    keep_prob -- placeholder for keep_probability\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    with g.as_default(): \n",
    "        W1=parameters[\"W1\"];\n",
    "        W2=parameters[\"W2\"];\n",
    "        W3=parameters[\"W3\"];\n",
    "        b1=parameters[\"b1\"];\n",
    "        b2=parameters[\"b2\"];\n",
    "        b3=parameters[\"b3\"];\n",
    "     # 1 layer\n",
    "        Z1=tf.add(tf.matmul(X,W1),b1);\n",
    "        A1=tf.nn.relu(Z1);\n",
    "        A1_drop=tf.nn.dropout(A1,keep_prob);\n",
    "     # 2 layer\n",
    "        Z2=tf.add(tf.matmul(A1_drop,W2),b2);\n",
    "        A2=tf.nn.relu(Z2);\n",
    "        A2_drop=tf.nn.dropout(A2,keep_prob);\n",
    "     # 3 layer\n",
    "        Z3=tf.add(tf.matmul(A2_drop,W3),b3);\n",
    "    return Z3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printResult(epoch,numberOfEpoch,trainLoss,validationLoss,validationAccuracy,g,train_accuracy):\n",
    "    with g.as_default():\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, numberOfEpoch),\n",
    "         '\\tTraining Loss: {:.3f}'.format(trainLoss),\n",
    "          '\\t Training_Accuracy{:.3f}%'.format(train_accuracy*100),    \n",
    "         '\\tValidation Loss: {:.3f}'.format(validationLoss),\n",
    "         '\\tVal_Accuracy: {:.2f}%'.format(validationAccuracy*100))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3,Y,g):\n",
    "    \"\"\"\n",
    "     Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (10, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    with g.as_default():  \n",
    "        logits = Z3;\n",
    "        labels = Y;\n",
    "        cost1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits =logits, labels = labels));\n",
    "   \n",
    "    \n",
    "    return cost1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Neural Network graph\n",
    "def model1(lambd,g,learning_rate_value,weight_nodes):\n",
    "    \n",
    "    with g.as_default():\n",
    "        numberOfClass = 10\n",
    "        imageSize = (28, 28)\n",
    "        features = np.prod(imageSize)\n",
    "        Input_Data,Input_Labels,keep_prob,l2_regulization=create_placeholder(features,numberOfClass,g); \n",
    "    # Placeolder for input data\n",
    "        parameters=initializer_parameters(features,weight_nodes,g); \n",
    "    # forward propogating\n",
    "        Z3=forward_propogation(parameters,Input_Data,g,keep_prob);\n",
    "    # computing the cost\n",
    "               \n",
    "        cost1=compute_cost(Z3,Input_Labels,g);\n",
    "        Total_l2_loss=(tf.nn.l2_loss(parameters[\"W1\"])+ tf.nn.l2_loss(parameters[\"W2\"])+tf.nn.l2_loss(parameters[\"W3\"]));\n",
    "        cost=tf.cond(l2_regulization>0,lambda : tf.reduce_mean(cost1+(lambd*Total_l2_loss)),lambda: cost1 );\n",
    "    # probability of outputs\n",
    "        probability=tf.nn.softmax(Z3);\n",
    "    # optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate_value).minimize(cost)\n",
    "    # accuracy\n",
    "        correct_prediction=tf.equal(tf.argmax(probability,axis=1),tf.argmax(Input_Labels,axis=1));\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32));\n",
    "    \n",
    "    return accuracy,optimizer,cost,keep_prob,l2_regulization,Input_Data,Input_Labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(learning_rate_value,l2_regulaizer,batch_size_value,num_epoches,keep_prob_rate,lambd):\n",
    "    num_layers=3\n",
    "    num_of_nodes=[30,30,10];\n",
    "    Learning_rate=learning_rate_value;\n",
    "    batch_size=batch_size_value;\n",
    "    num_of_epoches=num_epoches;\n",
    "    save_dir = 'C:/Users/SANYAM/Documents/mnist_dataset./save'\n",
    "    graph1 = tf.Graph()\n",
    "    accuracy,optimizer,cost,keep_prob,l2_regulization,Input_Data,Input_Labels=model1(lambd,graph1,\\\n",
    "                                                                                     learning_rate_value,num_of_nodes);\n",
    "    with tf.Session(graph=graph1) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        Total_cost=[];\n",
    "        \n",
    "        for epoch in range(num_of_epoches):\n",
    "        # training data & validation data\n",
    "            train_x, val_x, train_y, val_y = train_test_split(processedTrainData,one_hot_trainLabel,test_size = 0.3) ;\n",
    "            num_of_example=train_x.shape[0];\n",
    "            n1=(num_of_example/batch_size);\n",
    "        # training loss\n",
    "            epoche_num=0;\n",
    "            for i in range(0,num_of_example, batch_size):\n",
    "                       \n",
    "                if (i+batch_size)>num_of_example:   \n",
    "                    trainLoss, _ ,train_accuracy= sess.run([cost, optimizer,accuracy], feed_dict = {\n",
    "                Input_Data: train_x[i:num_of_example],\n",
    "                Input_Labels:train_y[i: num_of_example],\n",
    "                keep_prob:keep_prob_rate,\n",
    "                l2_regulization:l2_regulaizer     \n",
    "                })\n",
    "                else:\n",
    "                    trainLoss, _= sess.run([cost, optimizer], feed_dict = {\n",
    "                Input_Data:  train_x[i: i+batch_size],\n",
    "                Input_Labels: train_y[i: i+batch_size],\n",
    "                 keep_prob:keep_prob_rate,\n",
    "                l2_regulization:l2_regulaizer     \n",
    "                })\n",
    "                epoche_num+=(trainLoss/n1);\n",
    "            \n",
    "        # validation loss\n",
    "            valAcc, valLoss = sess.run([accuracy, cost], feed_dict ={\n",
    "            Input_Data: val_x,\n",
    "            Input_Labels: val_y,\n",
    "             keep_prob:keep_prob_rate,\n",
    "                l2_regulization:l2_regulaizer  \n",
    "        })\n",
    "            Total_cost.append(epoche_num);\n",
    "        \n",
    "        \n",
    "        # print out\n",
    "            printResult(epoch, num_of_epoches, trainLoss, valLoss, valAcc,graph1,train_accuracy)\n",
    "        # plotting the graph\n",
    "        plt.plot(np.squeeze(Total_cost));\n",
    "        plt.ylabel('cost');\n",
    "        plt.xlabel('iterations ');\n",
    "        plt.title(\"learning_rate\"+str(Learning_rate));\n",
    "    \n",
    "        # save\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 \tTraining Loss: 0.224 \t Training_Accuracy93.182% \tValidation Loss: 0.216 \tVal_Accuracy: 93.44%\n",
      "Epoch: 2/30 \tTraining Loss: 0.204 \t Training_Accuracy92.045% \tValidation Loss: 0.188 \tVal_Accuracy: 94.21%\n",
      "Epoch: 3/30 \tTraining Loss: 0.130 \t Training_Accuracy95.455% \tValidation Loss: 0.153 \tVal_Accuracy: 95.21%\n",
      "Epoch: 4/30 \tTraining Loss: 0.239 \t Training_Accuracy89.773% \tValidation Loss: 0.144 \tVal_Accuracy: 95.44%\n",
      "Epoch: 5/30 \tTraining Loss: 0.137 \t Training_Accuracy95.455% \tValidation Loss: 0.134 \tVal_Accuracy: 95.86%\n",
      "Epoch: 6/30 \tTraining Loss: 0.168 \t Training_Accuracy94.318% \tValidation Loss: 0.113 \tVal_Accuracy: 96.40%\n",
      "Epoch: 7/30 \tTraining Loss: 0.208 \t Training_Accuracy93.182% \tValidation Loss: 0.117 \tVal_Accuracy: 96.40%\n",
      "Epoch: 8/30 \tTraining Loss: 0.128 \t Training_Accuracy97.727% \tValidation Loss: 0.109 \tVal_Accuracy: 96.64%\n",
      "Epoch: 9/30 \tTraining Loss: 0.143 \t Training_Accuracy96.591% \tValidation Loss: 0.131 \tVal_Accuracy: 96.04%\n",
      "Epoch: 10/30 \tTraining Loss: 0.021 \t Training_Accuracy100.000% \tValidation Loss: 0.098 \tVal_Accuracy: 96.98%\n",
      "Epoch: 11/30 \tTraining Loss: 0.192 \t Training_Accuracy95.455% \tValidation Loss: 0.116 \tVal_Accuracy: 96.36%\n",
      "Epoch: 12/30 \tTraining Loss: 0.140 \t Training_Accuracy96.591% \tValidation Loss: 0.094 \tVal_Accuracy: 96.93%\n",
      "Epoch: 13/30 \tTraining Loss: 0.088 \t Training_Accuracy97.727% \tValidation Loss: 0.102 \tVal_Accuracy: 96.83%\n",
      "Epoch: 14/30 \tTraining Loss: 0.045 \t Training_Accuracy98.864% \tValidation Loss: 0.090 \tVal_Accuracy: 97.18%\n",
      "Epoch: 15/30 \tTraining Loss: 0.010 \t Training_Accuracy100.000% \tValidation Loss: 0.092 \tVal_Accuracy: 97.20%\n",
      "Epoch: 16/30 \tTraining Loss: 0.131 \t Training_Accuracy96.591% \tValidation Loss: 0.093 \tVal_Accuracy: 97.12%\n",
      "Epoch: 17/30 \tTraining Loss: 0.018 \t Training_Accuracy100.000% \tValidation Loss: 0.073 \tVal_Accuracy: 97.75%\n",
      "Epoch: 18/30 \tTraining Loss: 0.010 \t Training_Accuracy100.000% \tValidation Loss: 0.082 \tVal_Accuracy: 97.49%\n",
      "Epoch: 19/30 \tTraining Loss: 0.058 \t Training_Accuracy97.727% \tValidation Loss: 0.082 \tVal_Accuracy: 97.38%\n",
      "Epoch: 20/30 \tTraining Loss: 0.241 \t Training_Accuracy92.045% \tValidation Loss: 0.091 \tVal_Accuracy: 97.33%\n",
      "Epoch: 21/30 \tTraining Loss: 0.129 \t Training_Accuracy97.727% \tValidation Loss: 0.083 \tVal_Accuracy: 97.56%\n",
      "Epoch: 22/30 \tTraining Loss: 0.032 \t Training_Accuracy98.864% \tValidation Loss: 0.070 \tVal_Accuracy: 97.71%\n",
      "Epoch: 23/30 \tTraining Loss: 0.079 \t Training_Accuracy97.727% \tValidation Loss: 0.079 \tVal_Accuracy: 97.61%\n",
      "Epoch: 24/30 \tTraining Loss: 0.065 \t Training_Accuracy98.864% \tValidation Loss: 0.106 \tVal_Accuracy: 97.06%\n",
      "Epoch: 25/30 \tTraining Loss: 0.029 \t Training_Accuracy98.864% \tValidation Loss: 0.087 \tVal_Accuracy: 97.40%\n",
      "Epoch: 26/30 \tTraining Loss: 0.029 \t Training_Accuracy98.864% \tValidation Loss: 0.079 \tVal_Accuracy: 97.52%\n",
      "Epoch: 27/30 \tTraining Loss: 0.076 \t Training_Accuracy96.591% \tValidation Loss: 0.080 \tVal_Accuracy: 97.68%\n",
      "Epoch: 28/30 \tTraining Loss: 0.108 \t Training_Accuracy97.727% \tValidation Loss: 0.069 \tVal_Accuracy: 97.96%\n",
      "Epoch: 29/30 \tTraining Loss: 0.072 \t Training_Accuracy98.864% \tValidation Loss: 0.071 \tVal_Accuracy: 97.72%\n",
      "Epoch: 30/30 \tTraining Loss: 0.088 \t Training_Accuracy97.727% \tValidation Loss: 0.056 \tVal_Accuracy: 98.21%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VfWd//HXJzuBBAgkIGsAUWQRkIilVsWKCHYqtKN1\nGS1dba32Z3XajrWdqbW1i06t7dRWmbp2dBzXinXFvW5IQMIqsu8hIWwJIfvn98c94CUmuZeQm5vk\nvp+Px30k55zvued7vHLfOd9zvt+vuTsiIiItSYp3BUREpONTWIiISEQKCxERiUhhISIiESksREQk\nIoWFiIhEpLCQDsnMNprZtDgct8LMhrf3cUU6OoWFSBh37+Hu6+Ndj3BHG5xmlm5m95rZfjMrNrPr\nI5S/Lii3P9gvPWzbz81smZnVmdlNx3Aa0skpLCRhmFlyvOvQmJmlxOBtbwJGAkOBs4EfmtmMZo5/\nHnADcE5Qfjjws7Aia4EfAs/GoJ7SiSgspEMzsyQzu8HM1plZmZk9amY5YdsfC/4q3mdmb5rZmLBt\n95vZn83sOTM7AJwdrLvTzJ41s3IzW2BmI8L2cTM7Pmz/lspON7PVwbH/ZGZvmNk3IpzPV8zsbTP7\nnZmVATeZ2QgzezU4v11m9pCZ9QrK/xUYAjwTNJH9MFj/KTN7x8z2mlmRmU0NO8wc4OfuvsfdVwH/\nDXylmSrNAe5x9xXuvgf4eXhZd3/A3Z8Hyls6L+n6FBbS0X0XmA2cBQwA9gB3hm1/ntBf0XnAYuCh\nRvtfBtwCZAFvBesuIfTXc29Cfznf0sLxmyxrZn2Bx4EfAX2A1cCnozyn04D1QL/g/Qz4VXB+JwGD\nCV0d4O5XAJuBzwdNZLea2UBCf+n/AsgBvg88YWa5ZtYbOA4oCjteETCGpo1pomw/M+sT5blIglBY\nSEf3beDH7r7V3asJfYleeKj5xt3vdffysG3jzaxn2P5Pu/vb7t7g7lXBuqfc/X13ryMULhNaOH5z\nZc8HVrj7k8G2PwDFUZ7Tdnf/L3evc/eD7r7W3ee7e7W7lwK3EwrH5lwOPOfuzwXnNR8oDOrUIyiz\nL6z8PkJh2ZQeTZSlhfKSoGLRXirSloYCT5lZQ9i6ekJ//RYT+sv8IiAXOFSmLx9/6W1p4j3Dv9Qr\n+fgLtinNlR0Q/t7u7ma2teVTOeyIOplZP+D3wBmEvqSTCF1BNWcocJGZfT5sXSrwGlARLGcDVWG/\nN9eMVBFsJ6wsLZSXBKUrC+notgAz3b1X2CvD3bcRamKaBUwDegL5wT4Wtn+shlXeAQw6tGBmFr4c\nQeM6/TJYN87dswldObR0DluAvzb6b9Ld3X8d3HfYAYwPKz8eWNFMXVY0UXanu5dFeS6SIBQW0tHd\nBdxiZkMBgnb5WcG2LKAaKAMyCX3ptpdngXFmNjtoErsa6N/K98oi9Bf+vuB+xA8abd9J6CmlQ/4H\n+LyZnWdmyWaWYWZTzexQWD0I/MTMepvZKOCbwP3NHPtB4OtmNjq4qf6T8LJmlmpmGYS+K1KCY3W4\np8ok9hQW0tH9HpgHvGRm5cB7hG4QQ+iLbhOwDVgZbGsX7r6LUPPXrYTCajSh+wbVrXi7nwGnEGo6\nexZ4stH2XxH68t9rZt939y2ErqhuBEoJXWn8gI//Pf8UWEfov80bwG3u/gKAmQ0JnqoaEpzHC8E5\nvEboRvqmYP9D/hs4CFwK/Dj4/YpWnKN0cqbJj0SOnZklAVuBf3H31+JdH5G2pisLkVYKmoF6BT2e\nbyR0n6Hdrm5E2pPCQqT1phBq7tkFfB6Y7e4HzeyuoKmn8euu+FZXpPXUDCUiIhHpykJERCLqMp3y\n+vbt6/n5+fGuhohIp7Jo0aJd7p4bqVyXCYv8/HwKCwvjXQ0RkU7FzDZFU07NUCIiEpHCQkREIlJY\niIhIRAoLERGJSGEhIiIRKSxERCQihYWIiESU8GGxv6qWO17+iCVb9sa7KiIiHVbCh4U3wB0vr2Hh\nht3xroqISIeV8GGR3S2FtJQkSsqrIhcWEUlQCR8WZkZeVjol5a2Z4ExEJDEkfFgAobDYr7AQEWmO\nwgLIy8qgtEJhISLSHIUFkJedTsl+3bMQEWmOwoJQM9T+qjqqauvjXRURkQ5JYUGoGQqgVDe5RUSa\npLAAcrPTAfT4rIhIM2IaFmY2w8xWm9laM7uhie3fNrNlZrbEzN4ys9HB+nwzOxisX2Jmd8WynnlZ\nQVjoiSgRkSbFbFpVM0sG7gTOBbYCC81snruvDCv2sLvfFZS/ALgdmBFsW+fuE2JVv3CHmqHU10JE\npGmxvLKYDKx19/XuXgM8AswKL+Du+8MWuwMew/o0q0/3NJKTTM1QIiLNiGVYDAS2hC1vDdYdwcyu\nNrN1wK3A/wvbNMzMPjCzN8zsjKYOYGZXmlmhmRWWlpa2uqJJSUbfHmlqhhIRaUbcb3C7+53uPgL4\nN+AnweodwBB3nwhcDzxsZtlN7DvX3QvcvSA3N/eY6pGXlaFmKBGRZsQyLLYBg8OWBwXrmvMIMBvA\n3avdvSz4fRGwDjghRvUEIFfjQ4mINCuWYbEQGGlmw8wsDbgEmBdewMxGhi1+DlgTrM8NbpBjZsOB\nkcD6GNaVvKx0SnXPQkSkSTF7Gsrd68zsGuBFIBm4191XmNnNQKG7zwOuMbNpQC2wB5gT7H4mcLOZ\n1QINwLfdPaYTTuRlpVN2oIa6+gZSkuPeOici0qHELCwA3P054LlG6/4j7Pdrm9nvCeCJWNatsdzs\nDNxhV0UN/XtmtOehRUQ6PP0JHTjcMU9NUSIin6CwCKgXt4hI8xQWgbzsYDBBzWshIvIJCotAbg9d\nWYiINEdhEUhLSaJ3ZqruWYiINEFhEUa9uEVEmqawCJOXrV7cIiJNUViEyc1Kp1RzcYuIfILCIkxe\nVgalFdW4x2WkdBGRDkthESYvK53aemdPZW28qyIi0qEoLMLkaS5uEZEmKSzCHJ5eVX0tRESOoLAI\n8/H4UAoLEZFwCoswaoYSEWmawiJMZloKPdJT1AwlItKIwqKR3Kx0StUMJSJyBIVFI6G5uNUMJSIS\nTmHRSJ6uLEREPkFh0YgGExQR+SSFRSN52elU1tRTUV0X76qIiHQYCotGPp5eVfctREQOUVg0crgX\nt5qiREQOU1g08nHHPIWFiMghMQ0LM5thZqvNbK2Z3dDE9m+b2TIzW2Jmb5nZ6LBtPwr2W21m58Wy\nnuHUDCUi8kkxCwszSwbuBGYCo4FLw8Mg8LC7j3P3CcCtwO3BvqOBS4AxwAzgT8H7xVzPbqmkpSTp\n8VkRkTCxvLKYDKx19/XuXgM8AswKL+Du+8MWuwOHZh2aBTzi7tXuvgFYG7xfzJkZuT00vaqISLiU\nGL73QGBL2PJW4LTGhczsauB6IA34bNi+7zXad2AT+14JXAkwZMiQNqk0HJqLW81QIiKHxP0Gt7vf\n6e4jgH8DfnKU+8519wJ3L8jNzW2zOuVlpWswQRGRMLEMi23A4LDlQcG65jwCzG7lvm1KvbhFRI4U\ny7BYCIw0s2FmlkbohvW88AJmNjJs8XPAmuD3ecAlZpZuZsOAkcD7MazrEfKy0tl3sJaq2vr2OqSI\nSIcWs3sW7l5nZtcALwLJwL3uvsLMbgYK3X0ecI2ZTQNqgT3AnGDfFWb2KLASqAOudvd2++Y+1Nei\ntLyawTmZ7XVYEZEOK5Y3uHH354DnGq37j7Dfr21h31uAW2JXu+aF9+JWWIiIdIAb3B1RbtbHVxYi\nIqKwaNLHzVB6fFZEBBQWTerTPZ0k0/hQIiKHKCyakJxk9OmhvhYiIocoLJqRp7m4RUQOU1g0IxQW\nurIQEQGFRbPUi1tE5GMKi2bkZadTVlFNfYNHLiwi0sUpLJqRl5VOg0NZha4uREQUFs3I1VzcIiKH\nKSya8fFc3HoiSkREYdGMj+fi1pWFiIjCohmHxodSM5SIiMKiWekpyfTKTFUzlIgICosWaXpVEZEQ\nhUUL8rIyKNWjsyIiCouW6MpCRCREYdGC3Ox0SsurcVcvbhFJbAqLFuRlZVBT38C+g7XxroqISFwp\nLFqQp8dnRUQAhUWL1DFPRCREYdGCjzvmqa+FiCQ2hUUL8rI1mKCICMQ4LMxshpmtNrO1ZnZDE9uv\nN7OVZrbUzF4xs6Fh2+rNbEnwmhfLejanR3oKmWnJaoYSkYSXEqs3NrNk4E7gXGArsNDM5rn7yrBi\nHwAF7l5pZlcBtwIXB9sOuvuEWNUvWpqLW0QktlcWk4G17r7e3WuAR4BZ4QXc/TV3rwwW3wMGxbA+\nraLpVUVEYhsWA4EtYctbg3XN+TrwfNhyhpkVmtl7Zja7qR3M7MqgTGFpaemx17gJhzrmiYgkspg1\nQx0NM7scKADOCls91N23mdlw4FUzW+bu68L3c/e5wFyAgoKCmHSzzstK5/X9aoYSkcQWyyuLbcDg\nsOVBwbojmNk04MfABe5++E94d98W/FwPvA5MjGFdm5WXlcGBmnoOVNfF4/AiIh1CLMNiITDSzIaZ\nWRpwCXDEU01mNhG4m1BQlISt721m6cHvfYHTgfAb4+1GvbhFRGIYFu5eB1wDvAisAh519xVmdrOZ\nXRAUuw3oATzW6BHZk4BCMysCXgN+3egpqnZzeC5uNUWJSAKL6T0Ld38OeK7Ruv8I+31aM/u9A4yL\nZd2ilZcV6pineS1EJJGpB3cEGh9KRERhEVGvzFTSkpN0z0JEEprCIgIzI1e9uEUkwSksopCbpY55\nIpLYFBZR0FzcIpLoFBZRyMtWM5SIJDaFRRTysjLYU1lLTV1DvKsiIhIXCosoHHp8Vn0tRCRRKSyi\ncHh6VfXiFpEEFVVYmNlF0azrqg714lZfCxFJVNFeWfwoynVd0uHxoRQWIpKgWhwbysxmAucDA83s\nD2GbsoGEGbO7T/c0zKBUzVAikqAiDSS4HSgELgAWha0vB66LVaU6mpTkJPp0T9eVhYgkrBbDwt2L\ngCIze9jdayE01wQw2N33tEcFO4q8LIWFiCSuaO9ZzDezbDPLAYqA+8zs9hjWq8PJ01zcIpLAog2L\nnu6+H/gicJ+7TwKanIuiq8rTYIIiksCiDYsUMzsO+BLw9xjWp8PKy8pgV0UN9Q0e76qIiLS7aMPi\nZkLTo65z94VmNhxYE7tqdTx52enUNzi7D9TEuyoiIu0uqmlV3f0x4LGw5fXAP8eqUh3R4RnzyqsO\n9+gWEUkU0fbgHmRmT5lZSfB6wswGxbpyHUmuenGLSAKLthnqPmAeMCB4PROsSxiHBxPUvBYikoCi\nDYtcd7/P3euC1/1Abgzr1eHkhjVDiYgkmmjDoszMLjez5OB1OVAWy4p1NBmpyfTslqpmKBFJSNGG\nxdcIPTZbDOwALgS+EmknM5thZqvNbK2Z3dDE9uvNbKWZLTWzV8xsaNi2OWa2JnjNibKeMaXpVUUk\nUR3No7Nz3D3X3fMIhcfPWtrBzJKBO4GZwGjgUjMb3ajYB0CBu58MPA7cGuybA/wUOA2YDPw0GGYk\nrjS9qogkqmjD4uTwsaDcfTcwMcI+k4G17r7e3WuAR4BZ4QXc/TV3rwwW3wMOPWF1HjDf3XcHx50P\nzIiyrjGTl5VB8b4q3NUxT0QSS7RhkRT+l33wl3+kPhoDgS1hy1uDdc35OvD80exrZleaWaGZFZaW\nlkaozrE7NT+H7fuqeHPNrpgfS0SkI4k2LH4LvGtmPzeznwPvEDQZtYXghnkBcNvR7Ofuc929wN0L\ncnNj/3DWhZMGMbBXN3770mpdXYhIQokqLNz9QUKDCO4MXl90979G2G0bMDhseVCw7ghmNg34MXCB\nu1cfzb7tLS0liWvPGcnSrft4eVVJvKsjItJuor2ywN1Xuvsfg9fKKHZZCIw0s2FmlgZcQqhj32Fm\nNhG4m1BQhH/7vghMN7PeQfPX9GBd3H3xlIHk98nk9vkf0aBBBUUkQUQdFkfL3euAawh9ya8CHnX3\nFWZ2s5ldEBS7DegBPGZmS8xsXrDvbuDnhAJnIXBzsC7uUpKTuHbaSFbt2M/zy4vjXR0RkXZhXaXt\nvaCgwAsLC9vlWPUNznl3vAnAi987k+Qka5fjioi0NTNb5O4FkcrF7MqiK0tOMq6bdgJrSyp4pmh7\nvKsjIhJzCotWmjm2P6P6Z3HHyx9RV98Q7+qIiMSUwqKVkpKMf51+IhvLKnlycdwf1BIRiSmFxTGY\ndlIe4wf15PevrKGmTlcXItJ1KSyOgZlx3bknsG3vQR4t3BJ5BxGRTkphcYzOOiGXgqG9+eOra6mq\nrY93dUREYkJhcYzMjOunn0Dx/ioeXrA53tUREYkJhUUb+PSIvkwZ3oc/vb6Oypq6eFdHRKTNKSza\nyL9OP4FdFdU8+O6meFdFRKTNKSzaSEF+DmedkMvdb6yjolpXFyLStSgs2tD1557Anspa7ntrQ7yr\nIiLSphQWbWj84F5MO6kfc/+xnn2VtfGujohIm1FYtLHrzz2B8qo6/vLW+nhXRUSkzSgs2tjoAdl8\nbtxx3PvWBnYfqIl3dURE2oTCIga+N20kB2vr+dVzq+JdFRGRNqGwiIGR/bK4auoIHlu0lfkrd8a7\nOiIix0xhESPXnnMCJx2XzY+eXEpZRXXkHUREOjCFRYykpSTxu4vHs/9gHTc+tYyuMiOhiCQmhUUM\njeqfzfXTT+DFFTt56gPNeSEinZfCIsa+ecZwCob25qdPr2D73oPxro6ISKsoLGIsOcn47ZfGU+/O\nDx4voqFBzVEi0vkoLNrB0D7d+cnnRvP22jL++p4GGhSRzkdh0U4unTyYqSfm8qvnV7GutCLe1RER\nOSoxDQszm2Fmq81srZnd0MT2M81ssZnVmdmFjbbVm9mS4DUvlvVsD2bGrf98MhmpyVz/aBF19Zqz\nW0Q6j5iFhZklA3cCM4HRwKVmNrpRsc3AV4CHm3iLg+4+IXhdEKt6tqe87Ax+MXssRVv28ufX18W7\nOiIiUYvllcVkYK27r3f3GuARYFZ4AXff6O5LgYT5M/ufTh7ABeMH8PtX1rB82754V0dEJCqxDIuB\nwJaw5a3BumhlmFmhmb1nZrObKmBmVwZlCktLS4+lru3q5lljyOmexnX/t4Sq2vp4V0dEJKKOfIN7\nqLsXAJcBd5jZiMYF3H2uuxe4e0Fubm7717CVemWmceuFJ7OmpILfvrQ63tUREYkolmGxDRgctjwo\nWBcVd98W/FwPvA5MbMvKxdvUE/P4l9OG8Je3NvDe+rJ4V0dEpEWxDIuFwEgzG2ZmacAlQFRPNZlZ\nbzNLD37vC5wOrIxZTePkxvNPYkhOJtf93xL17haRDi1mYeHudcA1wIvAKuBRd19hZjeb2QUAZnaq\nmW0FLgLuNrMVwe4nAYVmVgS8Bvza3btcWHRPT+HOy06hoqqOy+9ZoNFpRaTDsq4yGmpBQYEXFhbG\nuxqtsmB9GV++932Oz+vB/175KbIzUuNdJRFJEGa2KLg/3KKOfIM7YZw2vA93XT6J1cXlfOP+Qg7W\n6AkpEelYFBYdxNmj8vjdxRNYuGk3Vz20iJq6hOl6IiKdgMKiA/n8+AH88gvjeH11Kdc/uoR6jVAr\nIh1ESrwrIEe6dPIQ9h+s5VfPf0hWRgq//MI4zCze1RKRBKew6IC+ddYI9lfVcudr68jOSOWGmaMU\nGCISVwqLDur7009k/8E67n5zPdndUrn67OPjXSURSWAKiw7KzPjZBWMor6rlthdXk52RwhVT8uNd\nLRFJUAqLDiwpybjtovFUVNfx70+vICsjldkTj2YsRhGRtqGnoTq41OQk/njZKUwZ3od/fayIm+at\nYMV2DW0uIu1LPbg7iYrqOn781DKeX1ZMTX0Do/pnceGkQcyeOJC+PdLjXT0R6aSi7cGtsOhk9lbW\n8EzRdh5fvI2iLXtJSTKmnpjLhZMG8dlR/UhL0cWiiERPYZEA1uws5/HFW3lq8TZKyqvplZnKrPED\nuHDSYMYOzNbjtiISkcIigdTVN/DW2l08sXgbL64opqaugRG53Zkxtj/TR/dn3MCeJCUpOETkkxQW\nCWrfwVr+vnQ7zy7dwYINu6lvcPpnZ3Du6H5MH9OP04b1UVOViBymsBD2Vtbw6oclvLRiJ298VMrB\n2nqyMlL47Kg8po/uz1kn5tIjXU9PiyQyhYUcoaq2nrfW7OKllcW8vKqE3QdqSEtO4tPH9+GiSYOZ\nPqYfqcm64hBJNAoLaVZ9g7No0x5eWlHM88uL2bb3IP2y07ls8lAunTyYvOyMeFdRRNqJwkKiUt/g\nvL66hAfe3cSbH5WSkmTMHHccX54ylIKhvfVElUgXF21YqME6wSUnGeec1I9zTurHhl0H+J/3NvFo\n4RaeKdrOqP5ZzPl0PrMmDCAzTf+riCQyXVnIJ1TW1PH0ku088M5GPiwuJysjhS8VDGbOlHyG9MmM\nd/VEpA2pGUqOmbtTuGkPD7yzkReWF5NkxnfOHsFVU0eQnpIc7+qJSBtQM5QcMzPj1PwcTs3PoXhf\nFb98bhV3vLyGvy/dwa++OI5T83PiXUURaSd6VlKi0r9nBn+4dCL3ffVUDtbUc9Fd73LjU8vYd7A2\n3lUTkXYQ07AwsxlmttrM1prZDU1sP9PMFptZnZld2GjbHDNbE7zmxLKeEr2zT8zjpevO5BufGcYj\n729m2u1v8NyyHXSV5kwRaVrMwsLMkoE7gZnAaOBSMxvdqNhm4CvAw432zQF+CpwGTAZ+ama9Y1VX\nOTrd01P4yT+N5umrP0NeVjrfeWgx33xwEdv3HozZMUvKq2hoUCCJxEssrywmA2vdfb271wCPALPC\nC7j7RndfCjQ02vc8YL6773b3PcB8YEYM6yqtMG5QT56++nRuPH8Ub60t5dzb3+D+tzdQ30Zf6u7O\nmx+V8qW732XyLa9w8dx32bDrQJu8t4gcnViGxUBgS9jy1mBdm+1rZleaWaGZFZaWlra6otJ6KclJ\nXHnmCOZfdxaT8nO46ZmVfPHP7/Ds0h0cqK5r1Xs2NDgvLN/BBX98my/f+z6byyr55hnDWF1czszf\nv8k9b7VdIIlIdDr101DuPheYC6FHZ+NcnYQ2OCeTB756KvOKtvOLZ1dx9cOLSU9J4swTcpk5tj/n\njOpHz8zUFt+jtr6BZ4q286fX17G2pIL8Ppn85p/H8YWJg0hLSeIbZwznxieX8fO/r+T5ZTu49cKT\nGZ7bo53OUCSxxTIstgGDw5YHBeui3Xdqo31fb5NaScyYGbMmDORz446jcNMeXlhezAvLi5m/cicp\nScanj+/LjDH9mT6m3xFTwVbV1vPYoq3c/cY6tu45yKj+Wfzh0omcP7Y/KWGDG/bLzuAvcwp46oNt\n3DRvBTN//w9+cN6JfPX0YSRrvg6RmIpZpzwzSwE+As4h9OW/ELjM3Vc0UfZ+4O/u/niwnAMsAk4J\niiwGJrn77uaOp055HVNDg1O0dS8vrAgFx6aySpIMCvJzmDGmP7X1DfzlrQ2UllczYXAvrjn7eM45\nKS/imFQl+6u48allvLyqhElDe3PrhSczQlcZIketQ/TgNrPzgTuAZOBed7/FzG4GCt19npmdCjwF\n9AaqgGJ3HxPs+zXgxuCtbnH3+1o6lsKi43N3Piwu5/nlxby4vJjVO8sBOP34Plw99XimjOhzVAMX\nujt/W7KNm+atpKq2nu9PP5GvfUZXGSJHo0OERXtSWHQ+60srqKlvYFT/7GN6n9BVxnJeXrWTU4b0\n4uZZYxkzQHOQi0RDYSEJxd15esl2fjpvBfsO1tK3R9rhoUomD8vhpOOydcUh0gSNDSUJxcyYPXEg\nnxnZl5dX7uT9Dbt5f+Nunl9eDEBWegqT8nsfDo+TB/XUYIgiR0FXFtKlbd97kIUbd7Ngw24WbtjN\nmpIKANJSkpgwqBcj8nowOKcbg3tnMjgnk0G9u9Gne5qasCRhqBlKpAm7D9SwcGMoOBZt3sPmskrK\nDtQcUSYzLZlBvY8MkJMH9eLU/PafObCiuo4lm/cyfnBPsjJa7qci0hpqhhJpQk73NM4b05/zxvQ/\nvO5AdR1b9xxky+5KtuypZMvug8HPShZs2E1F0BN9VP8svvLpfGZPHEhGauyasCqq63hl1U6eXbqD\n1z8qpaaugayMFK741FC+evowcrPSI7+JSBvTlYVIC9ydvZW1zF+5k3vf3sCHxeX0zkzl0slDuGLK\nUI7r2a1NjtNUQPTLTmfm2OP41PA+PFO0neeW7yA1OYmLJg3iyjOHM7RP9zY5tiQ2NUOJtDF3Z8GG\n3dz39gbmr9yJmTFjbH++dno+pww5+iaqlgLicycfx6QhvUkKe4Jrw64DzH1zPU8s2kpdQwPnjzuO\nb581grEDe0ZV93WlFSzatIfCjXv4qKSCz56Yx5xPD6VXZtpR/7cIt+dADfe/s5F5Rdv53rSRzJoQ\n7RBw0hEoLERiaMvuSh58dyOPLNxCeVUd4wb25Kun5/O5k48jPSWZuvoGdlXUUFJeRcn+akrKq0O/\nl1dTsr+a0vIqVhWXRwyIppTsr+Ketzfw0Hubqaiu44yRfblq6gimDP+4U2NVbT1FW/ZSuGkPizft\nYdHmPeytDE1U1SszlaE5mRRt3UdmWjKXTh7CN84YdtRXSTv3V/GXf6znoQWbqaypZ0DPDHbsr+IX\ns8fyL6cNbdV/V2l/CguRdnCguo4nP9jG/W9vYF3pAXplppKSZJQdqKGpf1o53dPIy0onNyudkXlZ\nzBzXP6qAaMq+g7U8tGAT9761kV0V1Ywf1JNThvbmg817WbF9H7X1oQoMz+3OpCG9KcjvzaShOQzv\n252kJGN1cTl3v7GOp4u2k2Qwe8JAvnXWCI7Pa3nYlM1lldz15joeL9xKvTsXjB/AVVNHMCQnk+88\ntJhXPyzhhpmj+PZZI476nKT9KSxE2lFDg/OPtbt4esk20lOSyctKJy87nbysDHKz0snLSqdvj3TS\nUtp+VoCq2nqeWLyVuW+uZ8e+KsYP6smkoTlMGtqbSUN7k9O95WamLbsrueetDTyycDPVdQ1MH92P\nq6Yez4TBvY4ot7q4nD+/vpZ5RdtJSUriooJBfOvMEQzpk3m4TG19A9c/WsQzRdv5ztQR/OC8Ezvt\nY8jvrivR98SEAAAMOklEQVTD3fn08X3jXZWYUliIJBh3p77Bjxip92iUVVTzwDsbeeDdTew7WMuU\n4X24auoIsjJS+NPr65i/cieZaclc/qmhfP0zw+iXndHk+9Q3OD/523L+9/3NXP6pIdx8wdhWXTnF\ny7rSCn757Cpe+bAEM7h51liu+FTXbVZTWIhIq1RU1/HI+5v5yz82ULy/CoCe3VL56un5zJmST+8I\nVyoQCq5fP/8hd7+5ntkTBnDbReNJbWWItZd9lbX8/pU1PPjuRjJSk7n67ONZtGk3L68q4XvTRnLt\nOSM77VVSS9TPQkRapUd6Ct84YzhfnpLPM0Xbqayp4wunDKJHevRfF2bGDTNHkd0tldteXE1FdT1/\nvGxiTPuntFZtfQMPL9jM717+iP0Ha7n41CFcf+4J5GalU1s/jBueWMYdL6+hrKKGmy4Yk7BjjCks\nRKRJaSlJ/POkQa3e38y4+uzjyc5I4d+fXsHX7l/I3C8XHFXoROLurCmp4LUPS6iormPMgJ6cPKgn\nx/XMiOoq4PXVJfzi2VWsLalgyvA+/Ps/jWb0gI9HQU5NTuI/LzqZPj3SmPvmenZX1nD7l8a3alyx\nhgbn+eXF1NTX8/mTB7S6uTBeFBYiElNXTMmnR0YK339sKZf/ZQH3f/XUY+rbcbCmnnfW7eK11SW8\n9mEp2/YeBCA5yQ7Pzd6nexpjB/Zk3MCejB34yQBZW1LOL55dxeurS8nvk8ncKyZx7uh+TQaMmXHj\n+SfRp3sav3r+Q/ZV1nLXFZOiDj13542PSvnNC6tZtWM/AH98dS0/nDGK6c0csyPSPQsRaRcvrijm\nuw9/wLC+3fnLnAIG9OoWdZPO5rJKXltdwqsflvDu+jJq6hrITEvm9OP78tlReUw9MZfemWms2rGf\n5dv2sXTrPpZt28eakopPBEjvzFSeWbqDzLRkrj1nJF+ekh/1U2qPFm7hR08uY+yAbO776uSIT5ot\n27qPXz2/infWlTE4pxvfn34i3VKT+c0LH7Ku9AAFQ3vzo/NHMWloTlTHjwXd4BaRDufttbv45oOF\nVNbUA9AtNZkeGSn0SE+he3oy3dNSyMpIoXt66GXAe+vLWFd6AIBhfbtz9ol5nD0ql8nDciI2B1XV\n1rMyCJBlQYBs3l3JF08ZyHXTTqBPj6MfZ2v+yp1c8/BiBvbuxl+/fhoDe32yM+OmsgP850sf8UzR\ndnK6p/Hdzx7PZacNOVzfuvoGHi3cyu9e/ojS8mrOG9OPH84YFZepgRUWItIhfbSznDc/KqWiuo6K\nqjoO1NRRUV3PgWC5ojq07kB1HdW1DUwY0isIiDyG9e0Y42G9v2E3X39gId3TUvjr1yczsl8WALsq\nqvnjq2t5aMEmUpKS+MYZw7jyzOHNjhhcWVPHPf/YwF1vrKOqroFLTh3MtdNGkpfV9GPJsaCwEBGJ\noZXb9zPnvvepqWvgzstOYfHmPdwdfOlffOpgvnfOSPKa6YvS2K6Kav7rlTU8tGAzaSlJfOOM4Vx5\n5vBP3BeprW+gqraeqtpDP0O/p6ZYq6cnVliIiMTY5rJKrrh3AZvKKgGYMaY/3z/vxIhDpjRn464D\n3PbSap5duoPsjBSyu6UeEQ51DU1/X08Y3Iu/XX16q46psBARaQel5dXc/cY6Zo47jklDe7fJey7Z\nspf/eW8TDe5kpCaTkZJMt7QkMlKSQ8upScHP0KtPjzROGdK6YyssREQkomjDonP1ChERkbiIaViY\n2QwzW21ma83shia2p5vZ/wXbF5hZfrA+38wOmtmS4HVXLOspIiIti1kPbjNLBu4EzgW2AgvNbJ67\nrwwr9nVgj7sfb2aXAL8BLg62rXP3CbGqn4iIRC+WVxaTgbXuvt7da4BHgFmNyswCHgh+fxw4xzpL\n33cRkQQSy7AYCGwJW94arGuyjLvXAfuAPsG2YWb2gZm9YWZnNHUAM7vSzArNrLC0tLRtay8iIod1\n1BvcO4Ah7j4RuB542Mw+0ePE3ee6e4G7F+Tm5rZ7JUVEEkUsw2IbMDhseVCwrskyZpYC9ATK3L3a\n3csA3H0RsA44IYZ1FRGRFsQyLBYCI81smJmlAZcA8xqVmQfMCX6/EHjV3d3McoMb5JjZcGAksD6G\ndRURkRbE7Gkod68zs2uAF4Fk4F53X2FmNwOF7j4PuAf4q5mtBXYTChSAM4GbzawWaAC+7e67Wzre\nokWLdpnZpmOocl9g1zHs39F0tfOBrndOXe18oOudU1c7H/jkOUU1wXiX6cF9rMysMJpejJ1FVzsf\n6Hrn1NXOB7reOXW184HWn1NHvcEtIiIdiMJCREQiUlh8bG68K9DGutr5QNc7p652PtD1zqmrnQ+0\n8px0z0JERCLSlYWIiESksBARkYgSPiwiDaPeGZnZRjNbFgzv3ulmhDKze82sxMyWh63LMbP5ZrYm\n+Nk2U5K1k2bO6SYz2xY2FP/58azj0TCzwWb2mpmtNLMVZnZtsL5Tfk4tnE9n/owyzOx9MysKzuln\nwfphwZQQa4MpItKier9EvmcR9BL/iLBh1IFLGw2j3umY2UagwN07ZWciMzsTqAAedPexwbpbgd3u\n/usg1Hu7+7/Fs55Ho5lzugmocPf/jGfdWsPMjgOOc/fFZpYFLAJmA1+hE35OLZzPl+i8n5EB3d29\nwsxSgbeAawmNt/ekuz8SzBVU5O5/jvR+iX5lEc0w6tLO3P1NQj36w4UPZ/8AoX/InUYz59RpufsO\nd18c/F4OrCI0inSn/JxaOJ9Oy0MqgsXU4OXAZwlNCQFH8RklelhEM4x6Z+TAS2a2yMyujHdl2kg/\nd98R/F4M9ItnZdrQNWa2NGim6hRNNo0FM1xOBBbQBT6nRucDnfgzMrNkM1sClADzCQ3KujeYEgKO\n4jsv0cOiq/qMu58CzASuDppAugwPtZ12hfbTPwMjgAmEhuX/bXyrc/TMrAfwBPA9d98fvq0zfk5N\nnE+n/ozcvT6YcXQQoZaUUa19r0QPi2iGUe903H1b8LMEeIrQ/ySd3c6gXflQ+3JJnOtzzNx9Z/CP\nuQH4bzrZ5xS0gz8BPOTuTwarO+3n1NT5dPbP6BB33wu8BkwBegVTQsBRfOclelhEM4x6p2Jm3YMb\ndJhZd2A6sLzlvTqF8OHs5wBPx7EubeLQl2rgC3Sizym4eXoPsMrdbw/b1Ck/p+bOp5N/Rrlm1iv4\nvRuhB3lWEQqNC4NiUX9GCf00FEDwKNwdfDyM+i1xrtIxCeb/eCpYTAEe7mznZGb/C0wlNJTyTuCn\nwN+AR4EhwCbgS5GGre9ImjmnqYSaNxzYCHwrrL2/QzOzzwD/AJYRmkYA4EZC7fyd7nNq4XwupfN+\nRicTuoGdTOjC4FF3vzn4jngEyAE+AC539+qI75foYSEiIpElejOUiIhEQWEhIiIRKSxERCQihYWI\niESksBARkYgUFiKAmb0T/Mw3s8va+L1vbOpYIp2JHp0VCWNmU4Hvu/s/HcU+KWFj7TS1vcLde7RF\n/UTiRVcWIoS+0INffw2cEcxdcF0wENttZrYwGEzuW0H5qcH8Bw8DS4N1fwsGb1xxaABHM/s10C14\nv4fCj2Uht5nZcgvNP3Jx2Hu/bmaPm9mHZvZQ0MMYM/t1MOfCUjPrdMNmS+eVErmISEK5gbAri+BL\nf5+7n2pm6cDbZvZSUHYyMNbdNwTLX3P33cHQCgvN7Al3v8HMrgkGc2vsi4R6B48n1LN7oZm9GWyb\nCIwBtgNvA6eb2SpCQ06Mcnc/NJSDSHvQlYVIy6YDXw6GeV4A9AFGBtveDwsKgP9nZkXAe4QGqBxJ\nyz4D/G8wUN1O4A3g1LD33hoMYLcEyAf2AVXAPWb2RaDymM9OJEoKC5GWGfBdd58QvIa5+6EriwOH\nC4XudUwDprj7eEJj7mQcw3HDx+qpBw7dF5lMaOKa2cALx/D+IkdFYSFypHIgK2z5ReCqYPhqzOyE\nYDTfxnoCe9y90sxGAZ8K21Z7aP9G/gFcHNwXyQXOBN5vrmLBXAs93f054HuEmrBE2oXuWYgcaSlQ\nHzQn3Q/8nlAT0OLgJnMpTU9D+QLwbTNbCqwm1BR1yFxgqZktdvd/CVv/FKH5BYoIjWr6Q3cvDsKm\nKVnA02aWQeiK57rWnaLI0dOjsyIiEpGaoUREJCKFhYiIRKSwEBGRiBQWIiISkcJCREQiUliIiEhE\nCgsREYno/wPwvvCPvdXgdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x711970c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model(learning_rate_value=0.01,l2_regulaizer=False,batch_size_value=128,num_epoches=30,keep_prob_rate = 1.0,lambd=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30]]\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant([1,2,3,4],shape=(1,4));\n",
    "b=tf.constant([1,2,3,4],shape=(4,1));\n",
    "c=tf.matmul(a,b);\n",
    "sess=tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(c));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
